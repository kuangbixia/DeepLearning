# 学习论文[DeepLabv1:Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs](https://arxiv.org/pdf/1412.7062v3.pdf)

## 摘要&介绍

### 1 深度卷积神经网络(DCNN:Deep Convolutional Neural Network)

- 在**高级视觉任务（图像级别）**中有state of art的性能
  - 优势
    - 对局部图像变换的**内在不变性/平移不变性**
    - 可以学习数据的分层抽象
  - 高级任务
    - 图像分类
    - 目标检测
    - 细粒度分类（？）
- 在**低级任务（像素级别）**中表现不佳
  - 劣势
    - 高度抽象了空间细节信息
    - <u>**不能精确地定位空间的细节**</u>
  - 低级任务
    - 姿势估计
    - 语义分割
- DCNN最后一层的响应并不能充分地定位来精确地进行目标分割
  - 解决：将<u>**全连接CRF**</u>和**<u>DCNN最后一层的响应</u>**相结合

### 2 全连接条件随机场(CRF:Conditional Random Field)

#### (1) 随机场

​	由若干个位置组成的整体，每个位置按照某种分布**随机的赋予一个值**

#### (2) 马尔科夫随机场(MRF)

- 在一个随机场中，某个位置的赋值**只与它相邻的位置有关**
- 假设有X和Y两个随机变量，一般情况下，X是给定的，Y是输出，Y构成了一个马尔科夫随机场

#### (3) 条件随机场

- 在一个马尔科夫随机场中，**给定X时Y的条件概率的分布**
- 假设有X和Y两个随机变量，若Y构成一个马尔科夫随机场，则P(Y|X)构成条件随机场

#### (4) 全连接条件随机场

- 任意两个变量构成联系

### 3 将DCNN应用到图像标签化的两个技术障碍

#### (1) 信号下采样

- 最大池化和下采样的重复出现，导致**降低信号分辨率**
- **解决**：采用**"atrous"算法（空洞）**

#### (2) 空间不敏感性（空间不变性）

- 从分类器获得的以目标为中心的预测，要求空间变换不变性，导致**空间精度受到限制**
- **解决**：采用**全连接条件随机场**，来增强捕获细节的能力

### 4 DeepLab的三个优点

#### (1) 速度

"atrous"算法使得DCNN以0.125秒每帧的速度运行

#### (2) 精度

比第二好的方法超过了7.2%

#### (3) 简单

由两个模块组成：DCNNs和CRFs



## 相关工作

- DeepLabv1和**FCN**都是像素级别的
- DeepLabv1和**两阶段方法**形成对比
  - 两阶段方法：
    - 常用在带有DCNN的语义分割中，由<u>自底向上的图像分割</u>和<u>基于DCNN的区域分类</u>级联
    - 缺点：使得前端分割有潜在的错误
- 二阶池化法——second order pooling（Carreira等）
  - 著名的非DCNN先例
  - 给区域分配标签
- 一套基于CRF的分割（Cogswell等）
  - 基于DCNN的重新排序系统
  - 用来尝试解决前端分割的问题
- 使用**卷积计算DCNN特征**来实现密集**图像标签化**的方法
  - 在多图像分辨中应用DCNN&使用**分割树**平滑预测结果（Farabet等）
  - 在像素分类中将计算的中间特征图和DCNN连接（Hariharan等）
  - 按区域集中中间特征图（Dai等）
- 无分割技术（Long等的<u>FCN</u>）
  - 将DCNN直接应用到整个图像
  - 用卷积层取代DCNN最后的全连接层
- **平均场**应用在图像分割和边缘检测任务中
  - Krahenbuhl&Koltum证明了：这对全连接的CRF和语义分割十分有效
- **DeepLabv1和当时最好的模型最大的区别：**
  - 将**像素级别的CRF**和**基于DCNN的"unary terms"**（一元项）的结合



## 用于密集图像标签化的卷积神经网络

### 1 密集滑动窗口特征提取——基于空洞算法

#### (1) 将VGG的全连接层转换为卷积层

- 输出图像为原图像的1/32
- 缺点：产生**稀疏**计算的检测分数（32像素的步长）

#### (2) 更密集地计算分数（8像素的步长）

- **跳过**最后两个最大池化层的下采样

  - 输出图像为原图像的1/8（**1/32**\*2\*2=**1/8**），图像变大了

- 修改它们（最后的两个池化层）之后的卷积层过滤器——<u>**增大过滤器**</u>（不采用）

  - 最后的三个卷积层：2倍
  - 第一个全连接层：4倍

- **空洞算法**（采用）

  - **<u>保持过滤器（卷积核）不变</u>**
  - 使用 2 个像素的输入步长对特征图进行稀疏采样，**<u>增大接受野</u>**
  - 示意图

  ![](.\Figures\DeepLabv1\hole_algorithm.JPG)

  ![](.\Figures\DeepLabv1\hole_convolution.JPG)

- 本文**采用空洞算法**
  - 实现：
    - 使用Caffe框架
    - 在im2col()函数（多通道的特征图->向量）中添加**稀疏采样特征图**的选项option

#### (2) 微调VGG16

- 微调VGG16的模型权重，使它适用于图像分类任务

  - 将VGG16最后的**1000路**Imagenet分类器替换为**21路**
  - 损失函数的计算：
    - 对CNN的输出图像（1/8）上的每一个空间位置计算交叉熵的总和
    - 所有的位置和标签的权重是相等的
    - target也是原图像的大小的1/8
  - 优化：
    - 采用**SDG**优化目标函数
- 获得原图像大小的<u>类别分数图</u>
- 产生的1/8大小的分数图已经比较平滑
  - 只要通过简单的**双线性插值**提高8倍分辨率，计算成本可忽略
  - 对比之下，**FCN**由于没有采用空洞算法，产生了非常粗糙的分数图，迫使采用上采样，增加了网络复杂性和训练时间

### 2 用卷积网络来控制接受野的大小&加速密集的计算

#### (1) 将VGG的全连接层转换为卷积层的困难

- 网络的接受野通常比较大，会导致密集分数图的计算量很大
  - 比如，VGG的接受野为224x224 / 卷积模式下404x404（？），将VGG16的全连接层替换为卷积层后，对于第一个全连接层则需要4096个7x7的过滤器

#### (2) 解决——加速密集计算

- 对第一个全连接层进行下采样
  - 减小到 4x4 / 3x3 的大小，则网络的接受野减小到128x128 / 卷积模式下308x308（对应上面的例子）
  - 缩短了第一个全连接层的计算时间2-3倍
- 减少全连接层的通道数
  - 4096 -> 1024
  - 缩短了计算时间，且减少了内存占用

## 边界恢复：全连接CRF&多尺度预测

### 1 深度卷积神经网络&定位挑战/困难

#### (1) DCNN定位困难

- DCNN的分数图可以预测出目标的出现和它的粗糙位置，但不能精确定位它的轮廓
- 这就是卷积网络在**分类精度**和**定位精度**的矛盾：
  - 更深度的模型会有更多的最大池化层，对**分类**很有帮助
  - 但同时增加了不变性和，也需要很大的接受野，导致**很难**从最后输出的分数推断目标的**位置**

#### (2) 解决方法

- 最近提出的两个方向
  1. 利用卷积网络中的各层信息，更好地估计目标的边界
  2. 采用**超像素**表示法，将定位任务交给**低级的分割方法**（无语义的分割）
- 本文提出的新方法
  - [将**DCNN的识别能力**和**全连接CRF的精细定位**结合](#2 用于精确定位的CRF)
  - 优点：产生精确的语义分割结果，**恢复目标边界**，达到当时最好的细节上的水平

### 2 用于精确定位的CRF

#### (1) CRF的应用——通常用来平滑结果

- 传统用于**平滑有噪声的分割图**，这类模型包含耦合相邻节点的<u>"energy terms"（能量项）</u>，倾向于给空间上接近的像素分配相同的标签
- <u>短程（短范围）的CRF</u>主要用来清除弱分类器的虚假预测

#### (2) 改善局部结构

- 因为输出已经够平滑了，我们需要**恢复局部结构的细节**

- 将对比敏感的potential（？）和<u>局部范围的CRF</u>结合
  - 缺点：结构不简单，且需要解决离散优化问题
- [提出加入 全连接CRF(Krahenbuhl&Koltun等)](#(3) 全连接CRF)

#### (3) 全连接CRF

![](.\Figures\DeepLabv1\FC_CRF.JPG)

- 能量函数

  - 一元势函数
    $$
    \begin{align}
    &\theta_i(x_i)=-log{P(x_i)}\\
    &其中，P(x_i)是像素i被标签为x的概率（通过DCNN计算）\\\\
    \end{align}
    $$

  - 高斯核
    $$
    \begin{align}
    &k^m(f_i,f_j)=\omega_1 exp(-\frac{||p_i-p_j||^2}{2\sigma_\alpha^2}-\frac{||I_i-I_j||^2}{2\sigma_\beta^2})
    +\omega_2exp(-\frac{||p_i-p_j||^2}{2\sigma_\gamma^2})\\
    &其中，第一个核跟像素位置和像素颜色强度有关，第二个核只跟像素位置有关;\\
    &超参数\sigma_\alpha,\sigma_\beta和\sigma_\gamma控制高斯核的尺度\\\\
    \end{align}
    $$

    - ***高斯核（？）***

      

  - 二元势函数

    - 全连接 -> 即对于图像上的任意两个像素（实际上只考虑标签不同的两两像素）

    $$
    \begin{align}
    &\theta_{ij}(x_i,x_j)=\mu(x_i,x_j)\sum_{m=1}^K\omega_m\cdot k^m(f_i,f_j)\\
    &其中，当x_i\neq x_j时，\mu(x_i,x_j)=1，否则\mu(x_i,x_j)=0;\\
    &k^m(f_i,f_j)是高斯核，取决于f_i,f_j（为像素i和像素j提取的特征），通过\omega_m加权\\\\
    \end{align}
    $$

  - 能量函数
    $$
    \begin{align}
    &E(x)=\sum_i\theta_i(x_i)+\sum_{ij}\theta_{ij}(x_i,x_j)\\
    \end{align}
    $$
    

### 3 多尺度预测——提高边界定位的精度

- 将一个两层MLP添加到输入图像&前四个pool的每一个pool的输出
  - MLP：
    - 128个3x3的卷积过滤器
    - 128个1x1的卷积过滤器
  - 最后输入到softmax层的特征图共增加了128*5=640个通道



## 实验评估

### 1 数据集

​	PASCAL VOC2012

### 2 训练



### 3 验证集上的评估

### 4 多尺度特征

### 5 视野

### 6 Mean IoU

