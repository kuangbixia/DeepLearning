# 学习论文[DeepLabv1:Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs](https://arxiv.org/pdf/1412.7062v3.pdf)

- 作者：（2016）

  - Liang-Chieh Chen
  - George Papandreou
  - Iasonas Kokkinos
  - Kevin Murphy
  - Alan L.Yuile

  

## 摘要&介绍

### 1 深度卷积神经网络(DCNN:Deep Convolutional Neural Network)

- 在**高级视觉任务（图像级别，如图像分类）**中有state of art的性能
  - 优势
    - 对局部图像变换的**内在不变性/平移不变性**
    - 可以学习数据的分层抽象
- 在**低级任务（像素级别，如语义分割）**中表现不佳
  - 劣势
    - 高度抽象了空间细节信息
    - **不能精确地定位空间的细节**
    - **DCNN最后一层的响应并不能精确定位目标的边界**

### 2 将DCNN应用到图像标签化的两个技术障碍

#### (1) 信号下采样

- 最大池化和下采样的重复出现，导致**降低信号分辨率**
- **解决**：
  - 采用**"atrous"算法（空洞算法）**

#### (2) 空间不敏感性（平移不变性）

- 从分类器获得的以目标为中心的预测，需要空间变换的不变性，导致**空间精度受到限制**
- **解决**：
- 采用**全连接的二元条件随机场**，来增强捕获细节的能力
  - **<u>CRF</u>**
  - 在语义分割中应用广泛
    - 将多路分类器输出的**分数图**和超像素捕获的**低级信息**相结合
  - <u>**拓展：全连接条件随机场**</u>
  - **随机场**
      - 由若干个位置组成的整体，每个位置按照某种分布**随机的赋予一个值**
  
    - **马尔科夫随机场(MRF)**
    - 在一个随机场中，某个位置的赋值**只与它相邻的位置有关**
      - 假设有X和Y两个随机变量，一般情况下，X是给定的，Y是输出，Y构成了一个马尔科夫随机场
  
    - **条件随机场(CRF:Conditional Random Field)**
    - 在一个马尔科夫随机场中，**给定X时Y的条件概率的分布**
      - 假设有X和Y两个随机变量，若Y构成一个马尔科夫随机场，则P(Y|X)构成条件随机场
  
    - **全连接条件随机场**
      - 任意两个变量构成联系

### 3 DeepLab的三个优点

#### (1) 速度

"atrous"算法使得DCNN以0.125秒每帧的速度运行

#### (2) 精度

比第二好的方法超过了7.2%

#### (3) 简单

由两个模块组成：DCNNs和CRFs



## 相关工作

- DeepLabv1和**FCN**都是像素级别的
- DeepLabv1和**两阶段方法**形成对比
  - 两阶段方法：
    - 常用在带有DCNN的语义分割中，由<u>自底向上的图像分割</u>和<u>基于DCNN的区域分类</u>级联
    - 缺点：使得前端分割有潜在的错误
- 二阶池化法——second order pooling（Carreira等）
  - 著名的非DCNN先例
  - 给区域分配标签
- 一套基于CRF的分割（Cogswell等）
  - 基于DCNN的重新排序系统
  - 用来尝试解决前端分割的问题
- 使用**卷积计算DCNN特征**来实现密集**图像标签化**的方法
  - 在多图像分辨中应用DCNN&使用**分割树**平滑预测结果（Farabet等）
  - 在像素分类中将计算的中间特征图和DCNN连接（Hariharan等）
  - 按区域集中中间特征图（Dai等）
- 无分割技术（Long等的<u>FCN</u>）
  - 将DCNN直接应用到整个图像
  - 用卷积层取代DCNN最后的全连接层
- **平均场**应用在图像分割和边缘检测任务中
  - Krahenbuhl&Koltum证明了：这对全连接的CRF和语义分割十分有效
- **DeepLabv1和当时最好的模型最大的区别：**
  - 将**像素级别的CRF**和**基于DCNN的"unary terms"**（一元项）的结合



## 密集图像标签化：卷积神经网络

### 0 VGG16结构

<img src=".\Figures\FCN\VGG16.JPG" style="zoom:67%;" />

### 1 提取密集特征——空洞算法

#### (1) 将VGG的全连接层转换为卷积层

- 输出图像为原图像的1/32
- 缺点：产生**稀疏**计算的检测分数（32像素的步长）

#### (2) 改进：更密集地计算分数（8像素的步长）

- **跳过**最后两个最大池化层的下采样

  - 输出图像为原图像的1/8（**1/32**\*2\*2=**1/8**），图像变大了

- 修改它们（最后的两个池化层）之后的卷积层过滤器——<u>**增大过滤器**</u>（不采用）

  - 最后的三个卷积层：2倍
  - 第一个全连接层：4倍

- **空洞算法**（采用）

  - **<u>保持过滤器（卷积核）不变</u>**
  - 使用 2 个像素的输入步长对特征图进行**稀疏采样**
  - 作用：**增大接受野**
  - 示意图

  ![](.\Figures\DeepLabv1\hole_algorithm.JPG)

  ![](.\Figures\DeepLabv1\hole_convolution.JPG)

- 本文的实现**（采用空洞算法）**
  - 使用Caffe框架
  - 在im2col()函数（多通道的特征图->向量）中添加**稀疏采样特征图**的选项

#### (3) 微调VGG16

- 微调VGG16的模型权重，使它适用于图像分类任务

  - 将VGG16最后的**1000路**Imagenet分类器替换为**21路**
  - 损失函数的计算：
    - 对CNN的输出图像（1/8）上的每一个空间位置计算交叉熵的总和
    - 所有的位置和标签的权重是相等的
    - target也是原图像的大小的1/8
  - 优化：
    - 采用**SDG**优化目标函数
- 获得原图像大小的<u>类别分数图</u>
  - 产生的1/8大小的分数图已经比较平滑，只要通过简单的**双线性插值**提高8倍分辨率，计算成本可忽略
  - 对比之下，**FCN**由于没有采用空洞算法，产生了非常粗糙的分数图，不得不采用上采样（层融合），增加了网络复杂性和训练时间

### 2 控制接受野的大小&加速密集的计算

#### (0) 接受野的计算

- 有零填充

  ？？？

- 无零填充——Top To Down计算接受野
  $$
  \begin{align}
  &RF_i=KernelSize_i+Strides_i*(RF_{i+1}-1)\\\\
  &RF_i即指定一层网络在第i层的接受野
  \end{align}
  $$

  - VGG16的接受野计算（无零填充）

    - 比如，计算FC6的接受野，对于input的接受野为404x404，计算过程如下

      | 对于第i层 | 卷积核/池化核大小 | 步长（不考虑零填充） | 接受野大小      |
      | --------- | ----------------- | -------------------- | --------------- |
      | pool5     | 7x7               | 1                    | 7x7             |
      | conv5-3   | 2x2               | 2                    | 2+2*(7-1)=14    |
      | conv5-2   | 3x3               | 1                    | 3+1*(14-1)=16   |
      | conv5-1   | 3x3               | 1                    | 3+1*(16-1)=18   |
      | pool4     | 3x3               | 1                    | 3+1*(18-1)=20   |
      | conv4-3   | 2x2               | 2                    | 2+2*(20-1)=40   |
      | conv4-2   | 3x3               | 1                    | 3+1*(40-1)=42   |
      | conv4-1   | 3x3               | 1                    | 3+1*(42-1)=44   |
      | pool3     | 3x3               | 1                    | 3+1*(44-1)=46   |
      | conv3-3   | 2x2               | 2                    | 2+2*(46-1)=92   |
      | conv3-2   | 3x3               | 1                    | 3+1*(92-1)=94   |
      | conv3-1   | 3x3               | 1                    | 3+1*(94-1)=96   |
      | pool2     | 3x3               | 1                    | 3+1*(96-1)=98   |
      | conv2-2   | 2x2               | 2                    | 2+2*(98-1)=196  |
      | conv2-1   | 3x3               | 1                    | 3+1*(196-1)=198 |
      | pool1     | 3x3               | 1                    | 3+1*(198-1)=200 |
      | conv1-2   | 2x2               | 2                    | 2+2*(200-1)=400 |
      | conv1-1   | 3x3               | 1                    | 3+1*(400-1)=402 |
      | input     | 3x3               | 1                    | 3+1*(402-1)=404 |

      - VGG16每一层对于input的接受野如下图

<img src=".\Figures\DeepLabv1\vgg16_receptive_field.png" style="zoom:67%;" />

#### (1) 将VGG的全连接层转换为卷积层的困难

- 网络的接受野通常比较大，会导致密集分数图的计算量很大
  - 比如，VGG16的接受野为<u>224x224（有零填充，？）</u> / 404x404（卷积模式），将VGG16的全连接层替换为卷积层后，对于第一个全连接层则需要4096个7x7的过滤器

#### (2) 解决：

- 对第一个全连接层进行下采样
  - 过滤器从 7x7 减小到 4x4 的大小，则网络的接受野减小到<u>128x128（有零填充，？）</u> / 308x308（卷积模式）
  - 缩短了第一个全连接层的计算时间2-3倍
- 减少全连接层的通道数
  - 4096 -> 1024
  - 缩短了计算时间，且减少了内存占用

## 边界恢复：全连接CRF，多尺度预测

### 1 深度卷积神经网络的定位困难

#### (1) DCNN定位困难

- DCNN的分数图可以预测出目标的出现和它的粗糙位置，但**不能精确定位它的轮廓**
- 这就是卷积网络在**分类精度**和**定位精度**的矛盾：
  - 更深度的模型会有更多的最大池化层，对**分类**很有帮助
  - 但同时增加了不变性，以及有很大的接受野，导致**很难**从最后输出的分数推断目标的**精确位置**

#### (2) 解决方法

- 最近提出的两个方向
  1. 利用卷积网络中的各层信息（如FCN **层融合**），更好地估计目标的边界
  2. 采用**超像素**表示法，将定位任务交给**低级的分割方法**（无语义的分割）
- 本文提出的新方法
  - [将**DCNN的识别能力**和**全连接CRF的精细定位**结合](#2 用于精确定位的CRF)
  - 优点：产生精确的语义分割结果，**恢复目标边界**，达到当时最好的细节上的水平

### 2 全连接的CRF——用于精确定位

#### (1) CRF的应用

- 传统用于**平滑有噪声的分割图**，这类模型包含耦合相邻节点的<u>"energy terms"（能量项）</u>，倾向于**给空间上接近的像素分配相同的标签**
- 这些<u>**短程CRF**</u>主要用来清除弱分类器的虚假预测

#### (2) DCNN架构

- 和弱分类器在性质上不同
- DCNN可以产生分数图和语义标签预测

- DCNN输出的分数图非常平滑，产生的分类结果很均匀，边界模糊，我们需要**恢复局部结构的细节**
- 解决：
  - 将**<u>对比敏感的电势</u>**和**<u>短程CRF</u>**结合
    - 缺点：结构不简单，且需要解决离散优化问题
  - 为了克服**<u>短程CRF</u>**的局限性，提出加入**全连接CRF**(Krahenbuhl&Koltun等)，和DCNN结合

#### (3) 全连接CRF

![](.\Figures\DeepLabv1\FC_CRF.JPG)

- 采用**能量函数**
  $$
  \begin{align}
  &E(x)=\sum_i\theta_i(x_i)+\sum_{ij}\theta_{ij}(x_i,x_j)\\
  \end{align}
  $$

  - 一元势函数——来自DCNN的输出
    $$
    \begin{align}
    &\theta_i(x_i)=-log{P(x_i)}\\
    &其中，P(x_i)是像素i被标签为x的概率（通过DCNN计算）\\\\
    \end{align}
    $$

  - 二元势函数——描述两两像素之间的关系

    - 全连接条件随机场 -> 即一个元素与图像上的其他任意像素的关系（实际上只考虑标签不同的两两像素，如下公式所示）
      - 高斯核（？）

    $$
    \begin{align}
    &\theta_{ij}(x_i,x_j)=\mu(x_i,x_j)\sum_{m=1}^K\omega_m\cdot k^m(f_i,f_j)\\
    &其中，当x_i\neq x_j时，\mu(x_i,x_j)=1，否则\mu(x_i,x_j)=0;\\
    &k^m(f_i,f_j)是高斯核，取决于f_i,f_j（为像素i和像素j提取的特征），通过\omega_m加权\\\\
    \end{align}
    $$

    - 具体地：

      - 第一个核的作用：让位置和颜色相近的像素打上相似的标签
      - 第二个核的作用：相当于一个平滑项，在处理平滑时只考虑空间邻近性

      $$
      \begin{align}
      &\theta_{ij}(x_i,x_j)=\mu(x_i,x_j)
      \begin{bmatrix}
      \omega_1 exp(-\frac{||p_i-p_j||^2}{2\sigma_\alpha^2}-\frac{||I_i-I_j||^2}{2\sigma_\beta^2})
      +\omega_2exp(-\frac{||p_i-p_j||^2}{2\sigma_\gamma^2})
      \end{bmatrix}\\
      &其中，第一个核跟像素位置和像素颜色强度有关，第二个核只跟像素位置有关;\\
      &超参数\sigma_\alpha,\sigma_\beta和\sigma_\gamma控制高斯核的尺度\\\\
      \end{align}
      $$

- 由于 双边空间的高斯卷积 计算复杂，使用完全可分解的**平均场**来近似计算（？）
  $$
  b(X)=\prod_ib_i(x_i)
  $$
  

### 3 多尺度预测——用于提高边界定位精度

- 将一个两层MLP添加到输入图像和pool1、pool2、pool3、pool4的输出
  - MLP（两层）：
    1. 128个3x3的卷积过滤器
    2. 128个1x1的卷积过滤器
- 将MLP输出的特征图（5个）和主网络的最后一层输出的特征图结合
- 最后输入到softmax层的特征图共增加了128*5=640个通道


