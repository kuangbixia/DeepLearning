# 关于卷积网络中的maps

## 1 feature maps 特征图

- 对于卷积层的输入输出，数据是三维的。(channel, height, width)
- 因此，灰度图像的每次输入会产生一个feature map（只有一个通道），彩色图像的每次输入会产生三个feature map（三个通道）

## 2 belief maps 置信图

​	CNN网络中经过全连接层后，最终输出的特征图，通道数为类别个数



# 学习论文[DeepLabv3:Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1706.05587)

- 作者（2017，部分同DeepLabv2）
  - Liang-Chieh Chen
  - George Papandreou
  - Florian Schroff
  - Hartwig Adam



## 摘要&介绍

### 1 主要内容

#### (1) 重温空洞卷积（用处）

- 调整过滤器的接受野
- 控制DCNN输出特征图的分辨率

- ASPP解决多尺度图像问题：
  - 采用多个空洞卷积层并行处理

#### (2) 改进ASPP模块

- 用编码了全局上下文的特征图

#### (3) 丢弃CRF的后处理

### 2 DCNN应用到语义分割的两个挑战

#### (1) 由池化和卷积操作导致的特征图分辨率下降

- 具体的空间信息逐渐丢失
- 解决：
  - 去掉最后两个下采样层
  - **空洞卷积**：对其后的卷积层的过滤器上采样（不增加额外的参数），以更大的接受野，处理分辨率更高的特征图

#### (2) 不同尺度图像的输入

- 四种方法（如下图）
  
  <img src=".\Figures\DeepLabv3\four_methods_for_multiscale_images.JPG" style="zoom:67%;" />
  
  1. 图像金字塔
     - 对图像进行不同比例的缩放，分别提取特征后整合
  2. Encoder-Decoder 编码器-解码器结构
     - FCN中采用的方法
     - 对不同层的特征图进行上采样并融合，输出和原图像大小一样的特征图
  3. 空洞卷积
     - DeepLabv1中采用的方法
     - 将一个两层MLP添加到输入图像和pool1、pool2、pool3、pool4的输出
       - MLP（两层）：
         1. 128个3x3的卷积过滤器
         2. 128个1x1的卷积过滤器
     - 将MLP输出的特征图（5个）和主网络的最后一层输出的特征图结合
  4. ASPP:Atrous Spatial Pyramid Pooling 空洞空间金字塔
     - DeepLabv2中采用的方法
     - 不同的池化操作具有不同的采样率和接受野
     - **缺点：**
       - 当给3x3的卷积核设置一个很大的采样率时，会因为**图像边界效应**，导致无法捕获远程信息
     - **解决：**
       - 将3x3卷积退化成1x1卷积
       - 并将图像级别的特征加入到ASPP模块中

## 相关工作

​	全局特征（全局上下文交互）对语义分割中的像素分类很重要，以下是四种利用图像全局上下文信息进行语义分割的FCN网络。

### 1 Image Pyramid 图像金字塔

#### (1) 结构

- 使用同一个模型（共享同样的参数权重），构造适应不同尺度的输入图像的分支（如上图的子图a）
- 大尺度的分支（如上图的子图a左）输出的特征保留了小目标的细节信息，小尺度的分支（如上图的子图a右）输出的特征编码了远程（全局）的上下文
- 对输入的原图像进行不同比例的缩放，输入到不同的分支中，最后将各个分支输出的特征图（大小不同）整合

#### (2) 缺点

​	由于GPU内存的限制，不适用于更大型的（更深度的）DCNN。

### 2 Encoder-Decoder 编码器-解码器

#### (1) 结构

​	由两部分组成

1. encoder 编码器
   - 特征图的空间维度（大小）逐渐减小（如上图的子图b左）
   - 因此，编码器的更深层的输出就更容易捕获到更远程（全局）的信息
2. decoder 解码器
   - 图像的细节和空间维度（大小）逐渐恢复（如上图的子图b右）

### 3 Context Module 上下文模块

#### (1) 作用

​	级联一些额外的模块，用于编码远程（全局）的上下文

#### (2) 三种方法

1. 将DenseCRF（具有高维滤波算法）结合到DCNN
2. 结合CRF和DCNN：在DCNN的最高层的特征图（有**nClass**个通道的**belief map**）后增加几个额外的卷积层，来捕获上下文信息
3. 学习一个全局的稀疏的高维卷积，并结合高斯CRF和DCNN

### 4 Spatial Pyramid Pooling 空间金字塔池化

#### (1) ASPP结构（DeepLabv2）

​	通过并行（**并联**）的多个具有不同的采样率的空洞卷积层，来捕获不同尺度的信息（如上图的子图d）

#### (2) PSP:Pyramid Scene Parsing Net 金字塔场景解析网络

​	在多个网格尺度上进行空间池化

#### (3) 把空洞卷积作为SPP的上下文模块/工具（DeepLabv3）

- DeepLabv3提出一个通用框架，可以应用到任何网络
  - 级联模块结构
    - 对**ResNet**原网络中最后一个块（block），复制多个副本，并将它们级联（串联）起来
    - 级联模块的输入，**直接应用到特征图**上而不是置信图
  - **ASPP**模块
    - 重温包含了并行的多个空洞卷积层的ASPP
- 实验证明，进行**批量标准化训练**很重要
- 为了更好的捕获全局上下文，用**图像级别的特征**来增强ASPP

### 5 Atrous Convolution 空洞卷积

​	很多基于空洞卷积的模型已经被应用到语义分割中。

## 方法

### 1 空洞卷积——用于密集特征提取（同DeepLabv2）

- 已经证明，将DCNN转换成全卷积的形式，对语义分割很有效。
- 重复的最大池化层逐渐降低了输出特征图的分辨率（如，FCN中就在高度和宽度上都缩小到原图像的1/32，使用反卷积恢复分辨率）

#### (1) 结构（如下图）

<img src=".\Figures\DeepLabv3\atrous_convolution.JPG" style="zoom:67%;" />

- 表达式（同DeepLabv2）
  $$
  y[i]=\sum_{k=1}^Kx[i+r\cdot k]w[k]\\
  其中，r为步长
  $$

#### (2) 作用

- 标准的卷积中，r=1；空洞卷积中，**r（dilation_rate 扩张率/输入步长）**可以设置不同的值，来**修改过滤器的接受野大小**
- 空洞卷积可以通过设置output_stride来**恢复图像大小**
  - 如，DCNN输出的特征图是原图像的1/32，可以通过设置output_stride=32来恢复分辨率
- 空洞卷积可以**控制输出特征密集程度**（如下，增大特征密度），且不增加额外的参数
  - 如果想要输出的特征更密集（增大两倍），则将最后的最大池化（和卷积）的stride减为1（则不在上一层的1/16输出再减半），则之后的**卷积层的输入步长r增大为2**（由于输入的图像的分辨率增大了，由1/32增大到了1/16），同时设置output_stride=16恢复到原图像大小

### 2 采用空洞卷积更深入网络

<img src=".\Figures\DeepLabv3\go_deeper_with_atrous_convolution.JPG" style="zoom:67%;" />

#### (1) 串联结构

- 对**ResNet**原网络中最后一个块（Block4），复制多个副本（Block5-Block7），并将它们级联（**串联**）起来
- 没有采用空洞卷积时（如上图的子图a）：这些块中每个块包含三个 3x3 的卷积，且最后一个卷积中包含步长2（Block7除外）
  - 缺点：不断地缩小分辨率，使得细节信息逐渐丢失
- 采用空洞卷积（如上图的子图b）：输入步长/扩张率rate由输出步长output_stride决定，Block3之后的rate大于1

#### (2) 多重网格法

- **多重网格法**：采用一系列不同大小的网格。

- 基于多网格方法，本文对Block4-Block7设置不同的rate（如上图的子图b）

- 对Block4-Block7的每一块中的三个卷积层的单位rate定义为：

  - $$
    Multi\_Grid=(r_1,r_2,r_3)
    $$

- 每一个块中每一个卷积层的rate计算如下：

  - $$
    rates=rate\cdot Multi\_Grid
    $$

  - 如，output_stride=16, Multi_Grid=(1, 2, 4)，那么，Block4中，rate=2，则rates=2 · (1, 2, 4)=(2, 4, 8)

### 3 优化ASPP:Atrous Spatial Pyramid Pooling

<img src=".\Figures\DeepLabv3\ASPP.JPG" style="zoom:67%;" />

#### (1) ASPP结构（DeepLabv2）

- 将**并行的四个空洞卷积**分别应用到顶层输出的特征图（如上图a Atrous Spatial Pyramid Pooling）
  - 一个是：256个1x1过滤器的卷积
  - 三个是：256个3x3过滤器的卷积，rates=(6, 12, 18)，output_stride=16
- 优点：可以有效地捕获不同尺度的信息

#### (2) ASPP问题&解决

- 实验证明，采样率rate越大时，过滤器的有效权重的数量越少
  - 当rate的值接近于图像大小，3x3过滤器并没有捕获图像的全局上下文，而是退化为1x1的过滤器（因为只有过滤器的中间的权重有效
- 解决：
  - 采用**图像级别的特征**加强，来实现将全局上下文信息结合到模型中
    - 对模型最后的特征图进行**全局平均池化**
    - 将产生的图像级别的特征反馈到256个1x1过滤器的卷积层中（如上图b Image Pooling）
    - 而后通过双线性上采样恢复到指定大小
  - 最后concat将各个分支的结果（256个通道）整合后，还要经过一个256个1x1过滤器的卷积层，生成最后的结果