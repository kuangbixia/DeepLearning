# 细化[FCN](https://arxiv.org/abs/1411.4038)学习

## 1 量化评估指标

### (1) IoU/IU 交并比(Intersection over Union)

$$
IoU=\frac{target \cap prediction}{target \cup prediction}
$$

- 基于类进行计算，将每一类的IoU计算后，累加计算平均值 -> mean IoU均交并比

  - $$
    MIoU=\frac{1}{k+1}\sum_{i=0}^k\frac{n_{ii}}{\sum_{j=0}^kn_{ij}+\sum_{j=0}^kn_{ji}-n_{ii}}
    $$

  - $$
    其中，n_{ii}表示target中类别为i的像素预测为类别i的像素的个数\\
    \sum_{j=0}^kn_{ij}相当于target中类别为i的面积（单个类别的area\_lab），\\
    \sum_{j=0}^kn_{ji}相当于prediction中类别为i的面积（单个类别的area\_pred），\\
    n_{ii}相当于它们相交的面积（单个类别的area\_inter）
    $$

  - ```python
    def batch_intersection_union(output, target, nclass):
        """mIoU"""
        # inputs are numpy array, output 4D, target 3D
        mini = 1
        maxi = nclass
        nbins = nclass
        predict = torch.argmax(output, 1) + 1
        target = target.float() + 1
    
        predict = predict.float() * (target > 0).float()
        intersection = predict * (predict == target).float()
        # areas of intersection and union
        # element 0 in intersection occur the main difference from np.bincount. set boundary to -1 is necessary.
        area_inter = torch.histc(intersection.cpu(), bins=nbins, min=mini, max=maxi)
        area_pred = torch.histc(predict.cpu(), bins=nbins, min=mini, max=maxi)
        area_lab = torch.histc(target.cpu(), bins=nbins, min=mini, max=maxi)
        area_union = area_pred + area_lab - area_inter
        assert torch.sum(area_inter > area_union).item() == 0, "Intersection area should be smaller than Union area"
        return area_inter.float(), area_union.float()
    
    # 返回了统计了每个类别的像素的个数的Tensor
    inter, union = batch_intersection_union(pred, label, self.nclass)
    self.total_inter += inter
    self.total_union += union
    
    IoU = 1.0 * self.total_inter / (2.220446049250313e-16 + self.total_union)
    mIoU = IoU.mean().item()
    ```

    

### (2) pixcal accuracy 像素精度(PA)

$$
PA=\frac{\sum_{i=0}^{k}n_{ii}}{\sum_{i=0}^k \sum_{j=0}^kn_{ij}}\\
其中，n_{ii}表示target中类别为i的像素预测为类别i的像素的个数（correct）\\
\sum_{j=0}^kn_{ij}相当于target中类别为i的像素个数（labeled）
$$

```python
def batch_pix_accuracy(output, target):
    """PixAcc"""
    # inputs are numpy array, output 4D, target 3D
    predict = torch.argmax(output.long(), 1) + 1
    target = target.long() + 1

    pixel_labeled = torch.sum(target > 0).item()
    pixel_correct = torch.sum((predict == target) * (target > 0)).item()
    assert pixel_correct <= pixel_labeled, "Correct area should be smaller than Labeled"
    return pixel_correct, pixel_labeled

# 返回像素个数
correct, labeled = batch_pix_accuracy(pred, label)

self.total_correct += correct
self.total_label += labeled

pixAcc = 1.0 * self.total_correct / (2.220446049250313e-16 + self.total_label)  # remove np.spacing(1)
```



# 进一步实验

​	上周分别对FCN32s，FCN16s和FCN8s，在PASCAL VOC2012的数据集上做实验，得到输出效果图的直观上的对比情况，还没有进行数据上的细致分析。

## 1 loss曲线

## 2 评估

- FCN论文

| Methods | Backbone | DataSet | epochs | lr   | Mean IoU | pixAcc |
| ------- | -------- | ------- | ------ | ---- | -------- | ------ |
| FCN32s  | vgg16    | VOC2011 | ？     | ？   | 59.40    | 89.10  |
| FCN16s  | vgg16    | VOC2011 | ？     | ？   | 62.40    | 90.00  |
| FCN8s   | vgg16    | VOC2011 | ？     | ？   | 62.70    | 90.30  |

- [github](https://github.com/Tramac/awesome-semantic-segmentation-pytorch)

| Methods | Backbone | DataSet | epochs | lr     | Mean IoU | pixAcc |
| ------- | -------- | ------- | ------ | ------ | -------- | ------ |
| FCN32s  | vgg16    | VOC2012 | 60     | 0.0001 | 47.50    | 85.39  |
| FCN16s  | vgg16    | VOC2012 | 60     | 0.0001 | 49.16    | 85.98  |
| FCN8s   | vgg16    | VOC2012 | 60     | 0.0001 | 48.87    | 85.02  |

- 我的实验

| Methods | Backbone | DataSet | epochs | lr     | Mean IoU | pixAcc |
| ------- | -------- | ------- | ------ | ------ | -------- | ------ |
| FCN32s  | vgg16    | VOC2012 | 200    | 0.0001 | 46.55    | 86.04  |
| FCN16s  | vgg16    | VOC2012 | 200    | 0.0001 | 49.57    | 87.53  |
| FCN8s   | vgg16    | VOC2012 | 200    | 0.0001 | 50.01    | 87.74  |