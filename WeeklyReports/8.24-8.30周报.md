- 本周主要阅读学习论文DeepLabv1和DeepLabv2（还没看完），发现v2更像是对v1的补充，以及提出ASPP来解决不同尺度图像的问题



# 学习论文[DeepLabv1:Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs](https://arxiv.org/pdf/1412.7062v3.pdf)

## 摘要&介绍

### 1 深度卷积神经网络(DCNN:Deep Convolutional Neural Network)

- 在**高级视觉任务（图像级别）**中有state of art的性能
  - 优势
    - 对局部图像变换的**内在不变性/平移不变性**
    - 可以学习数据的分层抽象
  - 高级任务
    - 图像分类
    - 目标检测
    - 细粒度分类
- 在**低级任务（像素级别）**中表现不佳
  - 劣势
    - 高度抽象了空间细节信息
    - <u>**不能精确地定位空间的细节**</u>
  - 低级任务
    - 姿势估计
    - 语义分割
- DCNN最后一层的响应并不能充分地定位来精确地进行目标分割
  - 解决：将<u>**全连接CRF**</u>和**<u>DCNN最后一层的响应</u>**相结合

### 2 将DCNN应用到图像标签化的两个技术障碍

#### (1) 信号下采样

- 最大池化和下采样的重复出现，导致**降低信号分辨率**
- **解决**：采用**"atrous"算法（空洞）**

#### (2) 空间不敏感性（空间不变性）

- 从分类器获得的以目标为中心的预测，要求空间变换不变性，导致**空间精度受到限制**

- **解决**：采用**全连接条件随机场**，来增强捕获细节的能力

  - **全连接条件随机场(CRF:Conditional Random Field)**

    - **随机场**
      - 由若干个位置组成的整体，每个位置按照某种分布**随机的赋予一个值**

    - **马尔科夫随机场(MRF)**
      - 在一个随机场中，某个位置的赋值**只与它相邻的位置有关**
      - 假设有X和Y两个随机变量，一般情况下，X是给定的，Y是输出，Y构成了一个马尔科夫随机场

    - **条件随机场**
      - 在一个马尔科夫随机场中，**给定X时Y的条件概率的分布**
      - 假设有X和Y两个随机变量，若Y构成一个马尔科夫随机场，则P(Y|X)构成条件随机场

    - **全连接条件随机场**
      - 任意两个变量构成联系

### 3 DeepLab的三个优点

#### (1) 速度

"atrous"算法使得DCNN以0.125秒每帧的速度运行

#### (2) 精度

比第二好的方法超过了7.2%

#### (3) 简单

由两个模块组成：DCNNs和CRFs



## 相关工作

- DeepLabv1和**FCN**都是像素级别的
- DeepLabv1和**两阶段方法**形成对比
  - 两阶段方法：
    - 常用在带有DCNN的语义分割中，由<u>自底向上的图像分割</u>和<u>基于DCNN的区域分类</u>级联
    - 缺点：使得前端分割有潜在的错误
- 二阶池化法——second order pooling（Carreira等）
  - 著名的非DCNN先例
  - 给区域分配标签
- 一套基于CRF的分割（Cogswell等）
  - 基于DCNN的重新排序系统
  - 用来尝试解决前端分割的问题
- 使用**卷积计算DCNN特征**来实现密集**图像标签化**的方法
  - 在多图像分辨中应用DCNN&使用**分割树**平滑预测结果（Farabet等）
  - 在像素分类中将计算的中间特征图和DCNN连接（Hariharan等）
  - 按区域集中中间特征图（Dai等）
- 无分割技术（Long等的<u>FCN</u>）
  - 将DCNN直接应用到整个图像
  - 用卷积层取代DCNN最后的全连接层
- **平均场**应用在图像分割和边缘检测任务中
  - Krahenbuhl&Koltum证明了：这对全连接的CRF和语义分割十分有效
- **DeepLabv1和当时最好的模型最大的区别：**
  - 将**像素级别的CRF**和**基于DCNN的"unary terms"**（一元项）的结合



## 用于密集图像标签化的卷积神经网络

### 1 密集滑动窗口特征提取——基于空洞算法

#### (1) 将VGG的全连接层转换为卷积层

- 输出图像为原图像的1/32
- 缺点：产生**稀疏**计算的检测分数（32像素的步长）

#### (2) 更密集地计算分数（8像素的步长）

- **跳过**最后两个最大池化层的下采样

  - 输出图像为原图像的1/8（**1/32**\*2\*2=**1/8**），图像变大了

- 修改它们（最后的两个池化层）之后的卷积层过滤器——<u>**增大过滤器**</u>（不采用）

  - 最后的三个卷积层：2倍
  - 第一个全连接层：4倍

- **空洞算法**（采用）

  - **<u>保持过滤器（卷积核）不变</u>**
  - 使用 2 个像素的输入步长对特征图进行稀疏采样，**<u>增大接受野</u>**
  - 示意图

  <img src="../Figures/DeepLabv1/hole_algorithm.JPG" style="zoom:67%;" />

  <img src="../Figures/DeepLabv1/hole_convolution.JPG" style="zoom: 50%;" />

- 本文**采用空洞算法**

  - 实现：
    - 使用Caffe框架
    - 在im2col()函数（多通道的特征图->向量）中添加**稀疏采样特征图**的选项option

#### (2) 微调VGG16

- 微调VGG16的模型权重，使它适用于图像分类任务

  - 将VGG16最后的**1000路**Imagenet分类器替换为**21路**
  - 损失函数的计算：
    - 对CNN的输出图像（1/8）上的每一个空间位置计算交叉熵的总和
    - 所有的位置和标签的权重是相等的
    - target也是原图像的大小的1/8
  - 优化：
    - 采用**SDG**优化目标函数
- 获得原图像大小的<u>类别分数图</u>
  - 产生的1/8大小的分数图已经比较平滑
  - 只要通过简单的**双线性插值**提高8倍分辨率，计算成本可忽略
  - 对比之下，**FCN**由于没有采用空洞算法，产生了非常粗糙的分数图，迫使采用上采样，增加了网络复杂性和训练时间

### 2 用卷积网络来控制接受野的大小&加速密集的计算

#### (1) 将VGG的全连接层转换为卷积层的困难

- 网络的接受野通常比较大，会导致密集分数图的计算量很大
  - 比如，VGG的接受野为224x224 / 卷积模式下404x404，将VGG16的全连接层替换为卷积层后，对于第一个全连接层则需要4096个7x7的过滤器

#### (2) 解决——加速密集计算

- 对第一个全连接层进行下采样
  - 减小到 4x4 / 3x3 的大小，则网络的接受野减小到128x128 / 卷积模式下308x308（对应上面的例子）
  - 缩短了第一个全连接层的计算时间2-3倍
- 减少全连接层的通道数
  - 4096 -> 1024
  - 缩短了计算时间，且减少了内存占用



## 边界恢复：全连接CRF&多尺度预测

### 1 深度卷积神经网络&定位困难

#### (1) DCNN定位困难

- DCNN的分数图可以预测出目标的出现和它的粗糙位置，但不能精确定位它的轮廓
- 这就是卷积网络在**分类精度**和**定位精度**的矛盾：
  - 更深度的模型会有更多的最大池化层，对**分类**很有帮助
  - 但同时增加了不变性和，也需要很大的接受野，导致**很难**从最后输出的分数推断目标的**位置**

#### (2) 解决方法

- 最近提出的两个方向
  1. 利用卷积网络中的各层信息，更好地估计目标的边界
  2. 采用**超像素**表示法，将定位任务交给**低级的分割方法**（无语义的分割）
- 本文提出的新方法
  - [将**DCNN的识别能力**和**全连接CRF的精细定位**结合](#2 用于精确定位的CRF)
  - 优点：产生精确的语义分割结果，**恢复目标边界**，达到当时最好的细节上的水平

### 2 用于精确定位的CRF

#### (1) CRF的应用——通常用来平滑结果

- 传统用于**平滑有噪声的分割图**，这类模型包含耦合相邻节点的<u>"energy terms"（能量项）</u>，倾向于给空间上接近的像素分配相同的标签
- <u>短程（短范围）的CRF</u>主要用来清除弱分类器的虚假预测

#### (2) 改善局部结构

- 因为输出已经够平滑了，我们需要**恢复局部结构的细节**

- 将对比敏感的potential（？）和<u>局部范围的CRF</u>结合
  - 缺点：结构不简单，且需要解决离散优化问题
- [提出加入 全连接CRF(Krahenbuhl&Koltun等)](#(3) 全连接CRF)

#### (3) 全连接CRF

<img src="../Figures/DeepLabv1/FC_CRF.JPG" style="zoom:67%;" />

- 能量函数

  - 一元势函数
    $$
    \begin{align}
    &\theta_i(x_i)=-log{P(x_i)}\\
    &其中，P(x_i)是像素i被标签为x的概率（通过DCNN计算）\\\\
    \end{align}
    $$

  - 高斯核
    $$
    \begin{align}
    &k^m(f_i,f_j)=\omega_1 exp(-\frac{||p_i-p_j||^2}{2\sigma_\alpha^2}-\frac{||I_i-I_j||^2}{2\sigma_\beta^2})
    +\omega_2exp(-\frac{||p_i-p_j||^2}{2\sigma_\gamma^2})\\
    &其中，第一个核跟像素位置和像素颜色强度有关，第二个核只跟像素位置有关;\\
    &超参数\sigma_\alpha,\sigma_\beta和\sigma_\gamma控制高斯核的尺度\\\\
    \end{align}
    $$

    - ***高斯核（？）***

      

  - 二元势函数

    - 全连接 -> 即对于图像上的任意两个像素（实际上只考虑标签不同的两两像素）

    $$
    \begin{align}
    &\theta_{ij}(x_i,x_j)=\mu(x_i,x_j)\sum_{m=1}^K\omega_m\cdot k^m(f_i,f_j)\\
    &其中，当x_i\neq x_j时，\mu(x_i,x_j)=1，否则\mu(x_i,x_j)=0;\\
    &k^m(f_i,f_j)是高斯核，取决于f_i,f_j（为像素i和像素j提取的特征），通过\omega_m加权\\\\
    \end{align}
    $$

  - 能量函数
    $$
    \begin{align}
    &E(x)=\sum_i\theta_i(x_i)+\sum_{ij}\theta_{ij}(x_i,x_j)\\
    \end{align}
    $$

### 3 多尺度预测——提高边界定位的精度

- 将一个两层MLP添加到输入图像&前四个pool的每一个pool的输出
  - MLP：
    - 128个3x3的卷积过滤器
    - 128个1x1的卷积过滤器
  - 最后输入到softmax层的特征图共增加了128*5=640个通道



# 学习论文[DeepLabv2:Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs](https://arxiv.org/pdf/1606.00915.pdf)

## 摘要&介绍

### 1 三个贡献

#### (1) 空洞卷积

- 控制特征图的分辨率
- 不增加参数的前提下扩大过滤器的接受野，包含更大的上下文

#### (2) 空洞空间金字塔池化(ASPP:Atrous Spatial Pyramid Pooling)

- 多尺度分割
- ASPP用过滤器以多种采样率和有效的视野探测卷积特征层，捕获不同尺度的目标和图像上下文

#### (3) 结合DCNN和CRF来改进对象边界的定位

### 2 将DCNN应用到语义分割的三个困难

#### (1) 降低特征图的分辨率（DeepLabv1中提到）

- 最大池化下采样导致输出的特征图分辨率降低

- 解决：在最后的几个最大池化层中去掉下采样，并**在它之后的卷积层中对滤波器进行上采样（即空洞卷积）**，得到更密集的特征图，之后只要采用简单的双线性插值恢复到原图像大小
  - 在DeepLabv1中，是保持过滤器不变，**对特征图进行稀疏采样**

#### (2) 多尺度目标的存在

- 标准方法
  - 将图像不同缩放版本后交给DCNN，之后整合特征图/分数图
  - 缺点：计算量大
- 采用**空间金字塔池化(SPP)**
  - 在卷积之前以不同的采样率重新采样特征
  - 实现：
    - 并非真的对特征进行重采样，而是使用不同的并行的**具有不同的采样率的空洞卷积层**代替，称作**ASPP(空洞空间金字塔池化)**

#### (3) DCNN的不变性降低定位精度（DeepLabv1提到）

- 一种方法
  - 使用跳跃连接（像FCN）
- 采用更高效的方法
  - 使用CRF来增强捕获细节的能力
    - CRF已经广泛应用到语义分割：将多路分类器输出的类别分数图和低级信息结合
  - 使用**全连接的二元CRF**
    - 优点：很好的捕获边缘细节，适合长范围的依赖

### 3 DeepLab模型（DeepLabv1提到）

<img src="../Figures/DeepLabv2/deeplab_model.JPG" style="zoom:67%;" />

- 将全连接层转换为卷积层
- 通过空洞卷积层增大接受野（因为将最后两个下采样去掉了，图像缩小到1/8，非1/32，图像较大，见DeepLabv1）
- 通过简单的双线性插值（8x，扩大到原图像大小）
- 输入全连接CRF提高定位精度

### 4 DeepLabv2 vs DeepLabv1

- 通过扩展Caffe框架，实现提出的ASPP，更好地解决不同尺度图像分割问题



## 方法

### 1 空洞卷积——用于提取密集特征&扩大接受野

#### (1) 一维

<img src="../Figures/DeepLabv2/atrous_convolution.JPG" style="zoom:67%;" />

- 表达式
  $$
  y[i]=\sum_{k=1}^Kx[i+r\cdot k]w[k]\\
  其中，r为步长
  $$

#### (2) 二维

- 对过滤器进行**上采样**

  - 在过滤器中插入0值（如上图b）：k x k -> (k+(r-1)(k-1)) x (k+(r-1)(k-1))
  - 虽然增大了过滤器的大小，但是只需要考虑非零的值，所以过滤器的参数没有增加

- 直接在高分辨率的图像上进行密集特征提取（如下图下行）

  - DeepLabv1中提到去掉最后两个最大池化层中的下采样，则输出的图像是原图像的1/8，分辨率高
  - 在之后直接对高分辨率图像（1/8）进行空洞卷积比下采样后卷积再上采样（如下图上行，FCN）效果好很多

  <img src="../Figures/DeepLabv2/atrous_convolution_2D.JPG" style="zoom:67%;" />

### 2 ASPP——用于多尺度图像（待学习）

### 3 全连接CRF——用于恢复精确的边界（待学习）